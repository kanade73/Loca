import time
import argparse
from rich.panel import Panel

# --- Loca åˆæœŸåŒ– ---
import loca.config as config
config.setup_environment()

# --- ã‚³ã‚¢æ©Ÿèƒ½ ---
from loca.core.llm_client import chat_with_llm, extract_json_from_text
from loca.core.prompts import get_system_prompt
from loca.core.memory import MemoryManager
from loca.core.pro_agent import run_pro_mode

# --- ãƒ„ãƒ¼ãƒ« ---
from loca.tools.web_search import search_web
from loca.tools.commander import execute_command
from loca.tools.file_ops import read_file, write_file, read_directory
from loca.tools.git_ops import auto_commit

# --- UI ---
from loca.ui.header import print_header
from loca.ui.display import console, print_thought, print_command, print_error, get_user_input

# ==========================================
# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
# ==========================================
def main(model_name: str, provider: str):
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    print_header(model_name=f"{model_name} ({provider.upper()})")
    
    # è¨˜æ†¶ç®¡ç†ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
    memory = MemoryManager()
    
    sys_prompt = get_system_prompt()
    messages = [sys_prompt]
    
    if "<project_guidelines>" in sys_prompt["content"]:
        console.print("[bold cyan]ğŸ§  Locaã®è¨˜æ†¶(loca_rules.md)ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼[/bold cyan]\n")
        
    needs_user_input = True 
    auto_mode = False

    while True:
        # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚º ---
        if needs_user_input:
            try:
                user_input = get_user_input()
            except (KeyboardInterrupt, EOFError):
                console.print("\n[dim]Shutting down agent...[/dim]")
                break
                
            if user_input.lower() in ['exit', 'quit']:
                console.print("[dim]Shutting down agent...[/dim]")
                break
                
            if not user_input:
                continue

            # ã‚³ãƒãƒ³ãƒ‰ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            if user_input.lower().strip() == "/auto":
                auto_mode = not auto_mode
                status = "ON (å…¨è‡ªå‹•ãƒ»æ‰¿èªã‚¹ã‚­ãƒƒãƒ—)" if auto_mode else "OFF (éƒ½åº¦ç¢ºèª)"
                console.print(f"\n[bold yellow]ğŸ¤– Auto Mode: {status}[/bold yellow]\n")
                needs_user_input = True
                continue

            is_ask_mode = False
            if user_input.startswith("/ask"):
                is_ask_mode = True
                question = user_input[4:].strip()
                messages[0] = get_system_prompt(is_ask_mode=True)
                enforced_question = f"{question}\n\n(â€»å¿…ãšã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã® <project_guidelines> ã«æŒ‡å®šã•ã‚ŒãŸæŸã‚„ãƒˆãƒ¼ãƒ³ã‚’å³æ ¼ã«å®ˆã£ã¦å›ç­”ã—ã¦ãã ã•ã„)"
                messages.append({"role": "user", "content": enforced_question})

            elif user_input.startswith("/remember "):
                rule = user_input[len("/remember "):].strip()
                if rule:
                    memory.remember(rule)
                    sys_prompt = get_system_prompt()
                    messages[0] = sys_prompt
                needs_user_input = True
                continue
                
            elif user_input.strip() == "/rules":
                memory.show_rules()
                needs_user_input = True
                continue
                
            elif user_input.startswith("/forget "):
                target = user_input[len("/forget "):].strip()
                if target:
                    memory.forget(target)
                    sys_prompt = get_system_prompt()
                    messages[0] = sys_prompt
                needs_user_input = True
                continue

            elif user_input.startswith("/commit"):
                auto_commit(model_name=model_name, provider=provider)
                needs_user_input = True
                continue
                
            elif user_input.startswith("/pro"):
                task = user_input[4:].strip()
                if not task:
                    console.print("[dim]ã‚¿ã‚¹ã‚¯ã®å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚(ä¾‹: /pro ãƒ†ãƒˆãƒªã‚¹ã‚’ä½œã£ã¦)[/dim]")
                    needs_user_input = True
                    continue
                
                final_files = run_pro_mode(task, model_name=model_name, provider=provider, auto_mode=auto_mode)
                if final_files:
                    messages.append({"role": "user", "content": f"(Proãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ: {task})"})
                    messages.append({"role": "assistant", "content": f"({len(final_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚)"})
                needs_user_input = True
                continue
                
        # --- AIæ€è€ƒãƒ•ã‚§ãƒ¼ã‚º ---
        start_time = time.time()
        with console.status("[bold cyan]AI is thinking...", spinner="dots"):
            response_data = chat_with_llm(messages, model_name=model_name, provider=provider, is_ask_mode=is_ask_mode)
        
        if is_ask_mode:
            raw_text = response_data.get("raw_response", "")
            parsed_json = extract_json_from_text(raw_text)
            
            if parsed_json and parsed_json.get("action") == "search_web":
                query = parsed_json.get("query", "")
                console.print(f"\n[bold cyan]ğŸ” æ¤œç´¢ä¸­:[/bold cyan] {query}")
                
                with console.status("[bold yellow]Webã‚’æ¤œç´¢ã—ã€å›ç­”ã‚’ç”Ÿæˆä¸­...", spinner="dots"):
                    search_result = search_web(query)
                    messages.append({"role": "assistant", "content": raw_text})
                    messages.append({"role": "user", "content": f"æ¤œç´¢çµæœ:\n{search_result}\n\nã“ã®çµæœã‚’è¸ã¾ãˆã¦ã€æœ€åˆã®è³ªå•ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ç›´æ¥ç­”ãˆã¦ãã ã•ã„ã€‚"})
                    
                    final_response = chat_with_llm(messages, model_name=model_name, provider=provider, is_ask_mode=True)
                    raw_text = final_response.get("raw_response", "æ¤œç´¢çµæœã®è§£é‡ˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    elapsed_time = time.time() - start_time

            console.print(f"[dim]â±ï¸ Answered in {elapsed_time:.1f}s[/dim]")
            console.print(Panel(raw_text, title="[bold blue]Loca[/bold blue]", border_style="blue"))
            messages.append({"role": "assistant", "content": raw_text})
            needs_user_input = True
            continue

        if "error" in response_data:
            print_error("ã†ã¾ãè§£é‡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            console.print(f"[dim]è©³ç´°: {response_data.get('raw_response', response_data)}[/dim]")
            needs_user_input = True
            continue

        thought = response_data.get("thought", "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãªã—")
        action = response_data.get("action", "none")
        args = response_data.get("args", {})
        elapsed_time = time.time() - start_time

        console.print(f"[dim]â±ï¸ Thought completed in {elapsed_time:.1f}s[/dim]")
        print_thought(thought)

        result_output = ""
        
        # --- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º ---
        if action == "run_command":
            cmd = args.get("command", "")
            if not cmd:
                result_output = "Error: commandå¼•æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            else:
                print_command(cmd)
                result_output = execute_command(cmd, auto_mode=auto_mode)
            
        elif action == "read_file":
            filepath = args.get("filepath", "")
            console.print(f"[bold blue]ğŸ“„ Reading file:[/bold blue] {filepath}")
            result_output = read_file(filepath)
            console.print(f"[dim]å†…å®¹ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚[/dim]")

        elif action == "write_file":
            filepath = args.get("filepath", "")
            content = args.get("content", "")
            console.print(f"[bold green]ğŸ“ Writing file:[/bold green] {filepath}")
            print_command(content)
            
            if auto_mode:
                confirm = 'y'
                console.print("[dim]ğŸ¤– Auto Mode: è‡ªå‹•ã§æ›¸ãè¾¼ã¿ã‚’è¨±å¯ã—ã¾ã—ãŸã€‚[/dim]")
            else:
                confirm = input("ç·¨é›†ã‚’è¨±å¯ã—ã¾ã™ã‹ï¼Ÿ [y/N]: ").strip().lower()
                
            if confirm == 'y':
                result_output = write_file(filepath, content)
                console.print(f"[dim]ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚[/dim]")
            else:
                result_output = "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚"
                console.print(f"[dim]æ›¸ãè¾¼ã¿ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚[/dim]")
        
        elif action == "read_directory":
            dir_path = args.get("dir_path", ".")
            console.print(f"[bold blue]ğŸ“‚ Reading directory:[/bold blue] {dir_path}")
            result_output = read_directory(dir_path)
            console.print(f"[dim]ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚[/dim]")

        elif action == "web_search":
            query = args.get("query", "")
            console.print(f"[bold cyan]ğŸ” Web Searching:[/bold cyan] {query}")
            result_output = search_web(query)
            console.print("[dim]æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸã€‚[/dim]")
        
        elif action == "none":
            pass
        else:
            result_output = f"Error: æœªçŸ¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ '{action}'"

        if action != "none":
            messages.append({"role": "assistant", "content": f"```json\n{{\"action\": \"{action}\", \"args\": {args}}}\n```"})
            messages.append({"role": "user", "content": f"å®Ÿè¡Œçµæœ:\n```\n{result_output}\n```\næ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚å®Œå…¨ã«é”æˆã•ã‚ŒãŸå ´åˆã®ã¿ action: none ã«ã—ã¦ãã ã•ã„ã€‚"})
            if result_output:
                console.print(f"\n[bold]Action Result:[/bold]\n[dim]{result_output}[/dim]\n")
            needs_user_input = False 
        else:
            messages.append({"role": "assistant", "content": f"Thought: {thought}\n(Action: none)"})
            console.print("[bold green]âœ… ã‚¿ã‚¹ã‚¯å®Œäº†[/bold green]\n")
            needs_user_input = True 

def cli():
    parser = argparse.ArgumentParser(description="Loca - Autonomous AI Coding Assistant")
    parser.add_argument("-p", "--provider", type=str, default="ollama", choices=["ollama", "openai", "anthropic", "gemini"], help="LLMã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼")
    parser.add_argument("-m", "--model", type=str, default="qwen2.5-coder:32b", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å")
    
    args = parser.parse_args()
    main(model_name=args.model, provider=args.provider)

if __name__ == "__main__":
    cli()