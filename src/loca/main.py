import time
import argparse
from rich.panel import Panel


# --- ã‚³ã‚¢æ©Ÿèƒ½ ---
from loca.core.llm_client import chat_with_llm, stream_chat_with_llm, extract_json_from_text, estimate_tokens
from loca.core.prompts import get_system_prompt
from loca.core.memory import MemoryManager
from loca.core.pro_agent import run_pro_mode

# --- ãƒ„ãƒ¼ãƒ« ---
from loca.tools.web_search import search_web
from loca.tools.commander import execute_command
from loca.tools.file_ops import read_file, write_file, edit_file, read_directory
from loca.tools.git_ops import auto_commit

# --- UI ---
from loca.ui.header import print_header
from loca.ui.display import console, print_thought, print_command, print_error, get_user_input
from rich.live import Live
from rich.markdown import Markdown

# ==========================================
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æº¢ã‚Œé˜²æ­¢ï¼‰
# ==========================================
MAX_EXCHANGES = 30       # 1ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®æœ€å¤§ã‚„ã‚Šã¨ã‚Šå›æ•°
MAX_MESSAGES = 60        # messagesãƒªã‚¹ãƒˆã®ä¸Šé™ï¼ˆã“ã‚Œã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’æ¨ã¦ã‚‹ï¼‰

def trim_messages(messages: list) -> list:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ãã ã‘ã®å®‰å…¨è£…ç½®ã€‚"""
    if len(messages) <= MAX_MESSAGES:
        return messages
    
    # system_prompt (messages[0]) + ç›´è¿‘ã®ã‚„ã‚Šã¨ã‚Šã ã‘æ®‹ã™
    trimmed = [messages[0]] + messages[-(MAX_MESSAGES - 1):]
    console.print(f"[dim]ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ•´ç†: å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ¨ã¦ã¾ã—ãŸ ({len(messages)} â†’ {len(trimmed)})[/dim]")
    return trimmed

# ==========================================
# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
# ==========================================
def main(model_name: str, provider: str):
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    print_header(model_name=f"{model_name} ({provider.upper()})")
    
    # è¨˜æ†¶ç®¡ç†ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
    memory = MemoryManager()
    
    sys_prompt = get_system_prompt()
    messages = [sys_prompt]
    
    if "<project_guidelines>" in sys_prompt["content"]:
        console.print("[bold cyan]ğŸ§  Locaã®è¨˜æ†¶(Loca.md)ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼[/bold cyan]\n")
        
    needs_user_input = True 
    auto_mode = False
    is_ask_mode = False
    exchange_count = 0  # LLMå‘¼ã³å‡ºã—å›æ•°ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    while True:
        # --- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç† ---
        messages = trim_messages(messages)
        
        # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚º ---
        if needs_user_input:
            try:
                user_input = get_user_input()
            except (KeyboardInterrupt, EOFError):
                console.print("\n[dim]Shutting down agent...[/dim]")
                break
                
            if user_input.lower() in ['exit', 'quit']:
                console.print("[dim]Shutting down agent...[/dim]")
                break
                
            if not user_input:
                continue

            # ã‚³ãƒãƒ³ãƒ‰ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            if user_input.lower().strip() == "/auto":
                auto_mode = not auto_mode
                status = "ON (å…¨è‡ªå‹•ãƒ»æ‰¿èªã‚¹ã‚­ãƒƒãƒ—)" if auto_mode else "OFF (éƒ½åº¦ç¢ºèª)"
                console.print(f"\n[bold yellow]ğŸ¤– Auto Mode: {status}[/bold yellow]\n")
                needs_user_input = True
                continue

            if user_input.lower().strip() == "/clear":
                sys_prompt = get_system_prompt()
                messages = [sys_prompt]
                exchange_count = 0
                console.print("\n[bold cyan]ğŸ”„ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚[/bold cyan]\n")
                needs_user_input = True
                continue

            is_ask_mode = False
            # /ask å¾Œã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæˆ»ã‚‰ãªã„ãƒã‚°é˜²æ­¢: æ¯å›é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã«å¾©å…ƒã™ã‚‹
            messages[0] = get_system_prompt()
            
            if user_input.startswith("/ask"):
                is_ask_mode = True
                question = user_input[4:].strip()
                messages[0] = get_system_prompt(is_ask_mode=True)
                enforced_question = f"{question}\n\n(â€»å¿…ãšã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã® <project_guidelines> ã«æŒ‡å®šã•ã‚ŒãŸæŸã‚„ãƒˆãƒ¼ãƒ³ã‚’å³æ ¼ã«å®ˆã£ã¦å›ç­”ã—ã¦ãã ã•ã„)"
                messages.append({"role": "user", "content": enforced_question})

            elif user_input.startswith("/remember "):
                rule = user_input[len("/remember "):].strip()
                if rule:
                    memory.remember(rule)
                    sys_prompt = get_system_prompt()
                    messages[0] = sys_prompt
                needs_user_input = True
                continue
                
            elif user_input.strip() == "/rules":
                memory.show_rules()
                needs_user_input = True
                continue
                
            elif user_input.startswith("/forget "):
                target = user_input[len("/forget "):].strip()
                if target:
                    memory.forget(target)
                    sys_prompt = get_system_prompt()
                    messages[0] = sys_prompt
                needs_user_input = True
                continue

            elif user_input.startswith("/commit"):
                auto_commit(model_name=model_name, provider=provider)
                needs_user_input = True
                continue
                
            elif user_input.startswith("/pro"):
                task = user_input[4:].strip()
                if not task:
                    console.print("[dim]ã‚¿ã‚¹ã‚¯ã®å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚(ä¾‹: /pro ãƒ†ãƒˆãƒªã‚¹ã‚’ä½œã£ã¦)[/dim]")
                    needs_user_input = True
                    continue
                
                final_files = run_pro_mode(task, model_name=model_name, provider=provider, auto_mode=auto_mode)
                if final_files:
                    messages.append({"role": "user", "content": f"(Proãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ: {task})"})
                    messages.append({"role": "assistant", "content": f"({len(final_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚)"})
                needs_user_input = True
                continue
                
        # --- AIæ€è€ƒãƒ•ã‚§ãƒ¼ã‚º ---
        # äº¤æ›å›æ•°ãƒã‚§ãƒƒã‚¯
        exchange_count += 1
        if exchange_count > MAX_EXCHANGES:
            console.print(f"\n[bold yellow]âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¸Šé™ ({MAX_EXCHANGES}å›) ã«é”ã—ã¾ã—ãŸã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚[/bold yellow]")
            console.print("[dim]æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚[/dim]\n")
            sys_prompt = get_system_prompt()
            messages = [sys_prompt]
            exchange_count = 0
            needs_user_input = True
            continue
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—è¡¨ç¤º
        token_count = estimate_tokens(messages)
        console.print(f"[dim]ğŸ“Š Tokens: ~{token_count} | Exchange: {exchange_count}/{MAX_EXCHANGES}[/dim]")
        
        start_time = time.time()
        
        # /ask ãƒ¢ãƒ¼ãƒ‰: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
        if is_ask_mode:
            raw_text = ""
            parsed_json = None
            
            # ã¾ãšé€šå¸¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ï¼ˆweb_searchã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®åˆ¤å®šã®ãŸã‚ï¼‰
            with console.status("[bold cyan]AI is thinking...", spinner="dots"):
                response_data = chat_with_llm(messages, model_name=model_name, provider=provider, is_ask_mode=True)
            
            raw_text = response_data.get("raw_response", "")
            parsed_json = extract_json_from_text(raw_text)
            
            if parsed_json and parsed_json.get("action") == "search_web":
                query = parsed_json.get("query", "")
                console.print(f"\n[bold cyan]ğŸ” æ¤œç´¢ä¸­:[/bold cyan] {query}")
                
                with console.status("[bold yellow]Webã‚’æ¤œç´¢ã—ã€å›ç­”ã‚’ç”Ÿæˆä¸­...", spinner="dots"):
                    search_result = search_web(query)
                    messages.append({"role": "assistant", "content": raw_text})
                    messages.append({"role": "user", "content": f"æ¤œç´¢çµæœ:\n{search_result}\n\nã“ã®çµæœã‚’è¸ã¾ãˆã¦ã€æœ€åˆã®è³ªå•ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ç›´æ¥ç­”ãˆã¦ãã ã•ã„ã€‚"})
                
                # æ¤œç´¢çµæœã‚’è¸ã¾ãˆãŸå›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¡¨ç¤º
                raw_text = ""
                console.print()
                with Live("", console=console, refresh_per_second=8) as live:
                    for chunk in stream_chat_with_llm(messages, model_name=model_name, provider=provider):
                        raw_text += chunk
                        live.update(Markdown(raw_text))
            else:
                # é€šå¸¸ã®/askå›ç­”: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å†åº¦ç”Ÿæˆ
                raw_text = ""
                console.print()
                with Live("", console=console, refresh_per_second=8) as live:
                    for chunk in stream_chat_with_llm(messages, model_name=model_name, provider=provider):
                        raw_text += chunk
                        live.update(Markdown(raw_text))

            elapsed_time = time.time() - start_time
            console.print(f"\n[dim]â±ï¸ Answered in {elapsed_time:.1f}s[/dim]")
            messages.append({"role": "assistant", "content": raw_text})
            needs_user_input = True
            continue

        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        with console.status("[bold cyan]AI is thinking...", spinner="dots"):
            response_data = chat_with_llm(messages, model_name=model_name, provider=provider, is_ask_mode=False)
        
        # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼ˆ1å›ã¾ã§ï¼‰
        if "error" in response_data and response_data.get("error") == "JSON_PARSE_ERROR":
            console.print("[dim]ğŸ”„ JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ä¸­...[/dim]")
            messages.append({"role": "assistant", "content": response_data.get("raw_response", "")})
            messages.append({"role": "user", "content": "ã‚ãªãŸã®å‰ã®å¿œç­”ã¯JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æŒ‡å®šã•ã‚ŒãŸJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å†åº¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"})
            with console.status("[bold cyan]AI is retrying...", spinner="dots"):
                response_data = chat_with_llm(messages, model_name=model_name, provider=provider, is_ask_mode=False)

        if "error" in response_data:
            print_error("ã†ã¾ãè§£é‡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            console.print(f"[dim]è©³ç´°: {response_data.get('raw_response', response_data)}[/dim]")
            needs_user_input = True
            continue

        thought = response_data.get("thought", "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãªã—")
        action = response_data.get("action", "none")
        args = response_data.get("args", {})
        elapsed_time = time.time() - start_time

        console.print(f"[dim]â±ï¸ Thought completed in {elapsed_time:.1f}s[/dim]")
        print_thought(thought)

        result_output = ""
        
        # --- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º ---
        if action == "run_command":
            cmd = args.get("command", "")
            if not cmd:
                result_output = "Error: commandå¼•æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            else:
                print_command(cmd)
                result_output = execute_command(cmd, auto_mode=auto_mode)
            
        elif action == "read_file":
            filepath = args.get("filepath", "")
            console.print(f"[bold blue]ğŸ“„ Reading file:[/bold blue] {filepath}")
            result_output = read_file(filepath)
            console.print(f"[dim]å†…å®¹ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚[/dim]")

        elif action == "write_file":
            filepath = args.get("filepath", "")
            content = args.get("content", "")
            console.print(f"[bold green]ğŸ“ Writing file:[/bold green] {filepath}")
            print_command(content)
            
            if auto_mode:
                confirm = 'y'
                console.print("[dim]ğŸ¤– Auto Mode: è‡ªå‹•ã§æ›¸ãè¾¼ã¿ã‚’è¨±å¯ã—ã¾ã—ãŸã€‚[/dim]")
            else:
                confirm = console.input("[bold]ç·¨é›†ã‚’è¨±å¯ã—ã¾ã™ã‹ï¼Ÿ [y/N]: [/bold]").strip().lower()
                
            if confirm == 'y':
                result_output = write_file(filepath, content)
                console.print(f"[dim]ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚[/dim]")
            else:
                result_output = "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚"
                console.print(f"[dim]æ›¸ãè¾¼ã¿ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚[/dim]")

        elif action == "edit_file":
            filepath = args.get("filepath", "")
            old_text = args.get("old_text", "")
            new_text = args.get("new_text", "")
            console.print(f"[bold yellow]âœï¸ Editing file:[/bold yellow] {filepath}")
            console.print(f"[dim]old_text: {old_text[:100]}{'...' if len(old_text) > 100 else ''}[/dim]")
            console.print(f"[dim]new_text: {new_text[:100]}{'...' if len(new_text) > 100 else ''}[/dim]")
            
            if auto_mode:
                confirm = 'y'
                console.print("[dim]ğŸ¤– Auto Mode: è‡ªå‹•ã§ç·¨é›†ã‚’è¨±å¯ã—ã¾ã—ãŸã€‚[/dim]")
            else:
                confirm = console.input("[bold]ç·¨é›†ã‚’è¨±å¯ã—ã¾ã™ã‹ï¼Ÿ [y/N]: [/bold]").strip().lower()
            
            if confirm == 'y':
                result_output = edit_file(filepath, old_text, new_text)
                console.print(f"[dim]ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¾ã—ãŸã€‚[/dim]")
            else:
                result_output = "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚"
                console.print(f"[dim]ç·¨é›†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚[/dim]")

        elif action == "read_directory":
            dir_path = args.get("dir_path", ".")
            console.print(f"[bold blue]ğŸ“‚ Reading directory:[/bold blue] {dir_path}")
            result_output = read_directory(dir_path)
            console.print(f"[dim]ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚[/dim]")

        elif action == "web_search":
            query = args.get("query", "")
            console.print(f"[bold cyan]ğŸ” Web Searching:[/bold cyan] {query}")
            result_output = search_web(query)
            console.print("[dim]æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸã€‚[/dim]")
        
        elif action == "none":
            pass
        else:
            result_output = f"Error: æœªçŸ¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ '{action}'"

        if action != "none":
            messages.append({"role": "assistant", "content": f"```json\n{{\"action\": \"{action}\", \"args\": {args}}}\n```"})
            messages.append({"role": "user", "content": f"å®Ÿè¡Œçµæœ:\n```\n{result_output}\n```\næ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚å®Œå…¨ã«é”æˆã•ã‚ŒãŸå ´åˆã®ã¿ action: none ã«ã—ã¦ãã ã•ã„ã€‚"})
            if result_output:
                console.print(f"\n[bold]Action Result:[/bold]\n[dim]{result_output}[/dim]\n")
            needs_user_input = False 
        else:
            messages.append({"role": "assistant", "content": f"Thought: {thought}\n(Action: none)"})
            console.print("[bold green]âœ… ã‚¿ã‚¹ã‚¯å®Œäº†[/bold green]\n")
            needs_user_input = True 

def cli():
    parser = argparse.ArgumentParser(description="Loca - Autonomous AI Coding Assistant")
    parser.add_argument("-p", "--provider", type=str, default="ollama", choices=["ollama", "openai", "anthropic", "gemini"], help="LLMã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼")
    parser.add_argument("-m", "--model", type=str, default="qwen2.5-coder:32b", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å")
    
    args = parser.parse_args()
    main(model_name=args.model, provider=args.provider)

if __name__ == "__main__":
    cli()